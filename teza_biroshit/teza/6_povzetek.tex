\section{POVZETEK (SUMMARY)}
\subsection{POVZETEK}
Populacija je skupina osebkov iste vrste, ki naseljujejo skupni prostor v danem času. Meje populacij navadno niso ostro določene, jih pa raziskovalci uokvirimo iz praktičnih razlogov. Populacijo lahko opišemo s pomočjo več parametrov, kot so rodnost, smrtnost, imigracija, emigracija in nenazadnje številčnost osebkov oziroma gostota. Velikost populacije lahko ocenimo na različne načine, npr. s pomočjo štetja, z metodo štetja na ploskvah, z vzorčenjem na točkah ali transektih ali s pomočjo metod lova-ponovnega ulova. Te metode imajo predpostavke o zaprtosti populacij, enaki ulovljivosti v danem odlovnem intervalu ter o točnosti oznak, s katerimi nedvoumno označimo osebke. Zaradi bioloških značilnosti vrste ali finančnih, časovnih in pravnih ovir včasih populacije ne moremo vzorčiti v celoti. V tem primeru nekateri osebki prehajajo rob območja vzorčenja in kršijo sicer povezani predpostavki zaprtosti populacije in enake verjetnosti ulovljivosti. Posledice prehajanja roba imenujemo učinek roba in je za oceno velikosti populacije nezaželen. Naš pristop k reševanju tega problema je uporaba Hugginsovega modela, ki sam po sebi ne deluje v prostorskem kontekstu, omogoča pa vključevanje individualnih spremenljivk. Ocena parametrov je tako lahko neposredno pod vplivom prostorskih statistik, ki jih vključimo v model. Cilj disertacije je izboljšati računanje gostote populacij, kjer med vzorčenjem prihaja do kršitve temeljnih predpostavk metode lova-ponovnega ulova. Na podlagi razdalj med vzorčenimi točkami smo izračunali individualno spremenljivko, ki ponazarja delež v prostoru in času, ko je osebek na voljo za odlov. Pričakovali smo, da bo imel model z vključeno individualno spremenljivko nižji AICc in bo tako boljši od modela, kjer te informacije nismo upoštevali. Z vključitvijo informacije o prehajanju roba smo pričakovali, da bomo izboljšali oceno verjetnosti ulovljivosti. Sklepali smo, da bomo oceno gostote izboljšali, ker bomo bolje poznali velikost dejanskega prispevnega območja osebkov v območju vzorčenja. Manjše kršitve zaradi učinka roba ne bi smele bistveno vplivati na pristranskost ocene gostote.

Učinkovitost popravka smo preverili s pomočjo simulacij na nivoju osebka. Za vsako simulacijo smo izračunali parametre modela po Hugginsu, in sicer verjetnost ulovljivosti in velikost ocenjene populacije s pripadajočimi intervali zaupanja. Pri prvem modelu ($M_0$) smo predpostavili, da je verjetnost ulovljivosti v prvem in vsakem nadaljnjem odlovnem intervalu enaka. Pri drugem modelu ($M_{sp}$) smo predpostavili, da je verjetnost ulovljivosti za posamezen osebek odvisna od individualne spremenljivke in sovpada z deležem, ki ga je osebek domnevno preživel znotraj območja vzorčenja. Izračunali smo še velikost populacije s pomočjo modela CAPWIRE, tako da smo predpostavili, da obstajata dve skupini osebkov, ki imata različni verjetnosti ulovljivosti. Individualno spremenljivko smo izračunali tako, da smo izračunali histogram prehojenih razdalj med vsemi možnimi točkami za posamezen osebek. Celice histograma smo dodatno utežili s pomočjo metrike, ki uteži razdalje glede na delež daljic, ki padejo v območje vzorčenja, če jih naključno postavimo in orientiramo v območju vzorčenja. Krajše razdalje so tako utežene bolj navzgor kot daljše razdalje. Uteženemu histogramu smo prilegli parametrično funkcijo, ki spominja na kumulativno Weibullovo porazdelitev s tremi parametri. Porazdelitev smo v izhodišču postavili v centroid točk, ki smo jih vzorčili za posamezen osebek, in izračunali delež, ki se nahaja znotraj območja vzorčenja. Na ta način smo v model vpeljali prostorsko komponento, ki je prej manjkala. Da bi imeli orientacijsko točko, s katero lahko primerjamo popravek, smo za računanje individualne spremenljivke uporabili dvorazsežno normalno porazdelitev, za parameter $\mu$ smo uporabili centroid vzorčenih točk, za parameter $\sigma$ pa simulirano vrednost. Tako smo dobili ``zlati standard'', ki nam je služil kot najboljši približek simuliranim vrednostim. Mere, s katerimi smo preverjali učinkovitost popravka, so ocenjena ulovljivost, AICc in gostota. Izvedli smo 6000 simulacij, kar je skupaj z MARK analizo trajalo več kot dva dni na zmogljivem računalniku s 24 sredicami. Ocenjena verjetnost ulovljivosti $p$ ni bila odvisna od števila simuliranih osebkov niti od načina izračuna individualne spremenljivke in je bila nekoliko nižja za model $M_{sp}$. Za $M_0$ in $M_{sp}$ je bila ocena $\hat{p}$ pod simulirano. Odstopanje od simulirane vrednosti je bilo največje za simulacije, kjer je bilo razmerje med velikostjo domačega okoliša in velikostjo območja vzorčenja največje. Natančnost ocene parametra $\hat{p}$ je bila v največji meri odvisna od števila odlovnih intervalov in števila generiranih osebkov. Gostoto smo izračunali tako, da smo ocenjeno velikost populacije delili z velikostjo območja vzorčenja, povečanega za percentil (50., 60., 70., 80., 90., 95., 99.) prehojene razdalje obeh funkcij, ki smo jih uporabili za izračun individualne spremenljivke, za standardni odklon simulirane velikosti domačega okoliša in za najdaljšo zaznano prehojeno razdaljo. Hugginsova modela $M_0$ in $M_{sp}$ sta dala nekoliko manj pristranske rezultate kot model CAPWIRE (TIRM). V primerih, ko je bilo razmerje med velikostjo domačega okoliša in velikostjo območja vzorčenja majhno, je bila pristranskost ocene gostote najmanjša, z večanjem tega razmerja pa je strmo naraščala. Za simulacije, kjer je bil model $M_0$ boljši od $M_{sp}$, je bil $\delta$AICc navadno majhen, do $\sim$ 2. V primerih, ko je bil $M_{sp}$ boljši od modela $M_0$, pa je bila razlika v AICc večja ($> 4$).

Ocena parametra verjetnosti ulovljivosti ($p$) je bila v splošnem pristranska za vse simulacije, še najbolj pa za tiste simulacije, kjer je razmerje med velikostjo domačega okoliša in velikostjo območja vzorčenja relativno veliko. Pojav je podoben za oba modela ($M_0$, $M_{sp}$), razlika pa se zmanjša za simulacije, kjer smo generirali več osebkov in vzorčili v več odlovnih intervalih. Razliko od simulirane vrednosti parametra $p$ pojasnjujemo s tem, da smo točke, ki smo jih vzorčili zunaj območja vzorčenja, krnili in posledično znižali simulirano vrednost. Iz podatkov, ki so nam na voljo, ne moremo na neodvisen način izluščiti, kakšna je bila dejanska simulirana vrednost, ampak verjetno ni daleč od tega, kar sta ocenila modela $M_0$ in $M_{sp}$ za simulacije z majhnim razmerjem med velikostjo domačega okoliša in velikostjo območja vzorčenja. Nismo zaznali razlik v rezultatih, kjer smo za računanje individualne spremenljivke uporabili normalno in empirično porazdelitev. Metrika AICc sicer v povprečju kaže, da je model $M_{sp}$ boljši, a so razlike v ocenah med tema modeloma v povprečju za praktične potrebe zanemarljivo majhne.
Teoretično gostoto osebkov smo izračunali tako, da smo simulirano število osebkov delili s površino območja, kjer smo generirali njihove centroide. To smo uporabili kot referenco, s katero smo primerjali ocenjeno gostoto. Naivna gostota je v splošnem zelo pristranska v simulacijah, ki so imele relativno veliko razmerje med velikostjo domačega okoliša in velikostjo območja vzorčenja. Pokazali smo, na kar v literaturi opozarjajo, da so nepopravljene ocene gostote lahko zelo pristranske navzgor. Z večanjem območja vzorčenja se pristranskost zmanjšuje in je najmanjša, ko ga povečamo za razdaljo 60. percentila v primeru, ko smo individualno spremenljivko izračunali s pomočjo normalne porazdelitve, in za razdaljo 80. percentila v primeru uporabe empirične porazdelitve. To namiguje, da je potrebno območje vzorčenja povečati za tako mero, da je vanj vključen večji delež domačega okoliša glede na pravo porazdelitev.
Razlike v oceni gostote med modeli niso bile velike. Vsi modeli precenjujejo oceno gostote, najbolj odstopajo ocene po modelu TIRM, po Hugginsu pa sta si modela $M_0$ in $M_{sp}$ podobna. Uporaba modela $M_{sp}$, kjer upoštevamo individualno spremenljivko, sama po sebi bistveno ne izboljša ocene. Še vedno moramo biti pazljivi pri tem, kako povečamo območje vzorčenja.

\subsection{SUMMARY}
Population is defined as individuals belonging to the same species that cohabit particular space in time. Though population borders are generally diffuse, they are delineated by researchers for practical purposes. A population can be described using different parameters, incl. fecundity, mortality, immigration, emigration and population size. Population size can be estimated using different approaches, either based on counts, distance-based or using mark-recapture models. Mark-recapture methods assume closure, equal probability of capture and no tag loss. Due to biological, financial or political reasons some populations can not be sampled in their entirety. As a result, some individuals traverse the sampling area border, thus violating the assumptions of closure and equal probability of capture. This causes the edge effect and has been a known issue for decades. In this study, we used the Huggins model to try and improve model parameters using a spatially explicit individual covariate. We expected to improve density estimates by expanding the sampling area based on the proportion of area/time where or when an individual was observable within the sampling polygon. A model that includes this individual covariate was expected to perform better in terms of AICc as well as be superior in estimating probability of capture $p$. Slight violations of model assumptions should have no discernable effect on model parameter estimates.

To assess the feasibility of this correction, we used a simulation-based approach. For each simulation we calculated model parameters ($\hat{p}$, $\hat{N}$) for Huggins and $\hat{N}$ for the CAPWIRE (TIRM) model, including 95 \% confidence intervals. For Huggins we constructed model $M_0$ where initial and all subsequent captures were assumed to be equal, and model $M_{sp}$ where initial capture and all subsequent captures were governed by an introduced individual covariate which described the proportion of area/time spent within the sampling polygon. TIRM formulation of the CAPWIRE model assumed two groups of individuals with each group having a distinct probability of capture. Individual covariate was calculated by calculating the histogram of pooled individual pairwise walked distances. A weight was used for each interval, depending on the proportion of randomly placed and oriented distances from that interval that fell entirely within the sampling polygon. A function which resembles a three-parameter cumulative Weibull distribution was fitted to this histogram. Origin point of the distribution was placed into the centroid calculated for each individual. Proportion of area/time within the sampling polygon was calculated and stored as the individual's covariate governed by space use. In order to obtain a reference point, a similar procedure was performed using a two-dimensional normal distribution that was parameterized using simulated $\sigma$ and calculated centroid for $\mu$. To discern any effect the correction would have, we compared AICc values of models $M_0$ and $M_{sp}$ as well as bias in density between all three models ($M_0$, $M_{sp}$, TIRM). In total 6000 simulations were performed, which took a little over 48 hours of computation time on a powerful 24-core computer. Estimated probability of capture ($\hat{p}$) did not depend on the number of simulated individuals nor on how individual covariate was computed (based on a two-dimensional normal or empirical distribution) and was lower for model $M_{sp}$. Parameter $\hat{p}$ never reached simulated value. Discrepancy between simulated and estimated probability of capture was greatest for simulations where ratio between home range size and sampling polygon size was highest. Precision of the estimate was most influenced by number of sampling sessions and number of simulated individuals. Density was compared against simulated density by calculating naïve density where estimated population size was divided by area of the sampling polygon. In addition, the sampling area was expanded by a percentile (50th, 60th, 70th, 80th, 90th, 95th, 99th) of the functions used to calculate the individual covariate, by the standard deviation of simulated home range size, and by maximal distance walked. Density estimates calculated from Huggins models ($M_0$, $M_{sp}$) yielded slightly less biased results compared to TIRM. Bias in density was smallest in cases where ratio between home range size and sampling polygon size was lowest and drastically increased with increased ratio. In cases where AICc was smaller for model $M_0$, $\delta$AICc was on average small and increased for cases where $M_{sp}$ was superior.

Probability of capture estimate $\hat{p}$ was biased in reference to the simulated value for all simulations. This was especially the case where ratio between home range size and sampling polygon size was high ($\rightarrow$ 1). The difference between models $M_0$ and $M_{sp}$ is small for practical purposes and even decreases when large numbers of individuals and many sampling sessions are used. This holds true for all simulations irrespective of the way the individual covariate has been calculated. The discrepancy between estimated and simulated value could be due to kerning of sampling points that have fallen outside of the sampling area. From the data at hand it is impossible to discern the true probability of capture; however, it is probably close to what has been estimated with models $M_0$ and $M_{sp}$ for cases where ratio between home range size and sampling polygon area was low. While AICc indicates that model $M_{sp}$ performed better, the effect size (difference between $M_0$ and $M_{sp}$ estimates) is quite small to have much practical effect.
To obtain theoretical density, we divided the number of simulated individuals with the area used to simulate their centroids. This was used as a ``gold standard'' against which we measured calculated densities. Naïve density (population size divided by sampling polygon size) proved to be very biased for all cases other than those where ratio between home range size and sampling polygon size was low. This is in accord with what is warned against in the literature. If density is calculated without accounting for sampling extent, it can be biased upward. By increasing sampling polygon size, the overestimated density is approaching estimated and is close to unbiased for cases where the sampling polygon has been expanded by the 60th percentile of the simulated two-dimensional normal distribution and the 80th percentile of the empirical distribution. This hints that the sampling polygon used to calculate density should include the majority of home ranges. Density estimates were similar between different models, but on average higher for the TIRM model. Using an individual covariate in a model does not by itself significantly improve the density estimate and special care still needs to be taken when increasing the sampling polygon area to compensate for estimating density.
